{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97283b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Time-series models\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet  # optional\n",
    "from xgboost import XGBRegressor  # optional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6fa77",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc60f434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-14</td>\n",
       "      <td>30755.0</td>\n",
       "      <td>30.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-15</td>\n",
       "      <td>43172.0</td>\n",
       "      <td>43.172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>17759.0</td>\n",
       "      <td>17.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>7545.0</td>\n",
       "      <td>7.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>6611.0</td>\n",
       "      <td>6.611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   amount     kwh\n",
       "0  2022-10-14  30755.0  30.755\n",
       "1  2022-10-15  43172.0  43.172\n",
       "2  2022-10-16  17759.0  17.759\n",
       "3  2022-10-17   7545.0   7.545\n",
       "4  2022-10-18   6611.0   6.611"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "#CPS historic data is only available as a part of an XML file\n",
    "\n",
    "# Load and parse the XML file\n",
    "\n",
    "def parse_cps_xml(path):\n",
    "    xml_file_path = path\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract interval readings\n",
    "    data_rows = []\n",
    "    for reading in root.iter():\n",
    "        if reading.tag.lower().endswith(\"intervalreading\"):\n",
    "            row_data = {}\n",
    "            for elem in reading.iter():\n",
    "                row_data[elem.tag.split('}')[-1]] = elem.text\n",
    "            data_rows.append(row_data)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data_rows)\n",
    "\n",
    "    # Convert Unix timestamp to datetime\n",
    "    df['start'] = pd.to_datetime(df['start'].astype(int), unit='s')\n",
    "\n",
    "    return df\n",
    "\n",
    "cps1=parse_cps_xml(\"/Users/lukeofthehill/repos/silly-things/CPS_Electric_15_Minute_03-31-2025_07-26-2025_20250726154824606_6601803.xml\")\n",
    "cps2=parse_cps_xml(\"/Users/lukeofthehill/repos/silly-things/CPS_Electric_15_Minute_04-05-2024_10-03-2024_20250726154734293_6601803.xml\")\n",
    "cps3=parse_cps_xml(\"/Users/lukeofthehill/repos/silly-things/CPS_Electric_15_Minute_04-11-2023_10-09-2023_20250726154546331_6601803.xml\")\n",
    "cps4=parse_cps_xml(\"/Users/lukeofthehill/repos/silly-things/CPS_Electric_15_Minute_10-02-2024_04-01-2025_20250726154807176_6601803.xml\")\n",
    "cps5=parse_cps_xml(\"/Users/lukeofthehill/repos/silly-things/CPS_Electric_15_Minute_10-08-2023_04-06-2024_20250726154700270_6601803.xml\")\n",
    "cps6=parse_cps_xml(\"/Users/lukeofthehill/repos/silly-things/CPS_Electric_15_Minute_10-13-2022_04-12-2023_20250726154008166_6601803.xml\")\n",
    "\n",
    "cps=pd.concat([cps1,cps2,cps3,cps4,cps5,cps6])\n",
    "cps=cps[['start','value']]\n",
    "cps=cps.rename(columns={'start':'date','value':'amount'})\n",
    "cps['amount']=cps['amount'].astype(float)\n",
    "cps['date']=pd.to_datetime(cps['date']).dt.date\n",
    "cps=cps.groupby('date')['amount'].sum().reset_index()\n",
    "cps['kwh'] = cps['amount'].astype(float) / 1000\n",
    "cps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf93df89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st_abb</th>\n",
       "      <th>st_code</th>\n",
       "      <th>county_name</th>\n",
       "      <th>fips</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>date</th>\n",
       "      <th>stability</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tavg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40331</th>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>Bexar</td>\n",
       "      <td>48029</td>\n",
       "      <td>78232</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>stable</td>\n",
       "      <td>18.881</td>\n",
       "      <td>27.319</td>\n",
       "      <td>23.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40332</th>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>Bexar</td>\n",
       "      <td>48029</td>\n",
       "      <td>78232</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>stable</td>\n",
       "      <td>-0.528</td>\n",
       "      <td>25.946</td>\n",
       "      <td>12.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40333</th>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>Bexar</td>\n",
       "      <td>48029</td>\n",
       "      <td>78232</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>stable</td>\n",
       "      <td>-3.637</td>\n",
       "      <td>8.600</td>\n",
       "      <td>2.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40334</th>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>Bexar</td>\n",
       "      <td>48029</td>\n",
       "      <td>78232</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>stable</td>\n",
       "      <td>-3.660</td>\n",
       "      <td>12.669</td>\n",
       "      <td>4.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40335</th>\n",
       "      <td>TX</td>\n",
       "      <td>48</td>\n",
       "      <td>Bexar</td>\n",
       "      <td>48029</td>\n",
       "      <td>78232</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>stable</td>\n",
       "      <td>2.056</td>\n",
       "      <td>18.852</td>\n",
       "      <td>10.454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      st_abb  st_code county_name   fips  zipcode        date stability  \\\n",
       "40331     TX       48       Bexar  48029    78232  2022-01-01    stable   \n",
       "40332     TX       48       Bexar  48029    78232  2022-01-02    stable   \n",
       "40333     TX       48       Bexar  48029    78232  2022-01-03    stable   \n",
       "40334     TX       48       Bexar  48029    78232  2022-01-04    stable   \n",
       "40335     TX       48       Bexar  48029    78232  2022-01-05    stable   \n",
       "\n",
       "         tmin    tmax    tavg  \n",
       "40331  18.881  27.319  23.100  \n",
       "40332  -0.528  25.946  12.709  \n",
       "40333  -3.637   8.600   2.481  \n",
       "40334  -3.660  12.669   4.504  \n",
       "40335   2.056  18.852  10.454  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Data\n",
    "temp=pd.read_csv(\"/Users/lukeofthehill/repos/silly-things/US Weather Data.csv\")\n",
    "temp=temp[temp['zipcode']==78232] # Keeping only my home county\n",
    "temp['date'] = pd.to_datetime(temp['date'], format='%Y%m%d').dt.date # Converting to an actual\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c193ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electrical Panel Replacement</td>\n",
       "      <td>2022-11-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dryer Outlet Replacement</td>\n",
       "      <td>2022-11-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Battery Panel Installation</td>\n",
       "      <td>2023-09-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AC Maintenance: Replace Temperature Sensor</td>\n",
       "      <td>2023-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reinsulation</td>\n",
       "      <td>2024-02-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         task        date\n",
       "0                Electrical Panel Replacement  2022-11-04\n",
       "1                    Dryer Outlet Replacement  2022-11-15\n",
       "2                  Battery Panel Installation  2023-09-22\n",
       "3  AC Maintenance: Replace Temperature Sensor  2023-12-04\n",
       "4                                Reinsulation  2024-02-28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Home maintenance tasks\n",
    "hw=pd.DataFrame({'task':[\"Electrical Panel Replacement\",\n",
    "                            'Dryer Outlet Replacement',\n",
    "                            \"Battery Panel Installation\",\n",
    "                            \"AC Maintenance: Replace Temperature Sensor\",\n",
    "                            \"Reinsulation\",\n",
    "                            \"AC Maintenance: New Fan\",\n",
    "                            \"Fence Replacement / Mulch\",\n",
    "                            \"Replaced Windows\",\n",
    "                            \"AC Maintenance: Hard Start Kit with/without Potential Relay\",\n",
    "                            \"New Water Heater\",\n",
    "                            \"AC Condensation Line Clog Work\"],\n",
    "                'date':['2022-11-04',\n",
    "                    '2022-11-15',\n",
    "                    '2023-09-22',\n",
    "                    '2023-12-04',\n",
    "                    '2024-02-28',\n",
    "                    '2024-03-28',\n",
    "                    '2025-04-01',\n",
    "                    '2025-04-25',\n",
    "                    '2025-04-29',\n",
    "                    '2025-05-20',\n",
    "                    '2025-07-11']})\n",
    "hw['date']=pd.to_datetime(hw['date'],format='%Y-%m-%d').dt.date\n",
    "hw.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1105090f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1j/lbm004rj00d8hcz0l4mz0w680000gn/T/ipykernel_60817/2116714797.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['task'].fillna('No Work',inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>amount</th>\n",
       "      <th>kwh</th>\n",
       "      <th>st_abb</th>\n",
       "      <th>st_code</th>\n",
       "      <th>county_name</th>\n",
       "      <th>fips</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>stability</th>\n",
       "      <th>tmin</th>\n",
       "      <th>...</th>\n",
       "      <th>task_ACMaintenanceNewFan</th>\n",
       "      <th>task_ACMaintenanceReplaceTemperatureSensor</th>\n",
       "      <th>task_BatteryPanelInstallation</th>\n",
       "      <th>task_DryerOutletReplacement</th>\n",
       "      <th>task_ElectricalPanelReplacement</th>\n",
       "      <th>task_FenceReplacement/Mulch</th>\n",
       "      <th>task_NewWaterHeater</th>\n",
       "      <th>task_NoWork</th>\n",
       "      <th>task_Reinsulation</th>\n",
       "      <th>task_ReplacedWindows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-10-14</td>\n",
       "      <td>30755.0</td>\n",
       "      <td>30.755</td>\n",
       "      <td>TX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Bexar</td>\n",
       "      <td>48029.0</td>\n",
       "      <td>78232.0</td>\n",
       "      <td>stable</td>\n",
       "      <td>20.021</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-10-15</td>\n",
       "      <td>43172.0</td>\n",
       "      <td>43.172</td>\n",
       "      <td>TX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Bexar</td>\n",
       "      <td>48029.0</td>\n",
       "      <td>78232.0</td>\n",
       "      <td>stable</td>\n",
       "      <td>20.702</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>17759.0</td>\n",
       "      <td>17.759</td>\n",
       "      <td>TX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Bexar</td>\n",
       "      <td>48029.0</td>\n",
       "      <td>78232.0</td>\n",
       "      <td>stable</td>\n",
       "      <td>22.647</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>7545.0</td>\n",
       "      <td>7.545</td>\n",
       "      <td>TX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Bexar</td>\n",
       "      <td>48029.0</td>\n",
       "      <td>78232.0</td>\n",
       "      <td>stable</td>\n",
       "      <td>18.304</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>6611.0</td>\n",
       "      <td>6.611</td>\n",
       "      <td>TX</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Bexar</td>\n",
       "      <td>48029.0</td>\n",
       "      <td>78232.0</td>\n",
       "      <td>stable</td>\n",
       "      <td>14.170</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   amount     kwh st_abb  st_code county_name     fips  zipcode  \\\n",
       "0  2022-10-14  30755.0  30.755     TX     48.0       Bexar  48029.0  78232.0   \n",
       "1  2022-10-15  43172.0  43.172     TX     48.0       Bexar  48029.0  78232.0   \n",
       "2  2022-10-16  17759.0  17.759     TX     48.0       Bexar  48029.0  78232.0   \n",
       "3  2022-10-17   7545.0   7.545     TX     48.0       Bexar  48029.0  78232.0   \n",
       "4  2022-10-18   6611.0   6.611     TX     48.0       Bexar  48029.0  78232.0   \n",
       "\n",
       "  stability    tmin  ...  task_ACMaintenanceNewFan  \\\n",
       "0    stable  20.021  ...                     False   \n",
       "1    stable  20.702  ...                     False   \n",
       "2    stable  22.647  ...                     False   \n",
       "3    stable  18.304  ...                     False   \n",
       "4    stable  14.170  ...                     False   \n",
       "\n",
       "   task_ACMaintenanceReplaceTemperatureSensor task_BatteryPanelInstallation  \\\n",
       "0                                       False                         False   \n",
       "1                                       False                         False   \n",
       "2                                       False                         False   \n",
       "3                                       False                         False   \n",
       "4                                       False                         False   \n",
       "\n",
       "   task_DryerOutletReplacement  task_ElectricalPanelReplacement  \\\n",
       "0                        False                            False   \n",
       "1                        False                            False   \n",
       "2                        False                            False   \n",
       "3                        False                            False   \n",
       "4                        False                            False   \n",
       "\n",
       "   task_FenceReplacement/Mulch  task_NewWaterHeater  task_NoWork  \\\n",
       "0                        False                False         True   \n",
       "1                        False                False         True   \n",
       "2                        False                False         True   \n",
       "3                        False                False         True   \n",
       "4                        False                False         True   \n",
       "\n",
       "   task_Reinsulation  task_ReplacedWindows  \n",
       "0              False                 False  \n",
       "1              False                 False  \n",
       "2              False                 False  \n",
       "3              False                 False  \n",
       "4              False                 False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combinind the data\n",
    "df=pd.merge(cps,temp,'left', on='date')\n",
    "df=pd.merge(df,hw,'left',on='date')\n",
    "df['task'].fillna('No Work',inplace=True)\n",
    "dummies=pd.get_dummies(df['task'],prefix='task')\n",
    "dummies.columns = dummies.columns.str.replace(' ', '')\n",
    "dummies.columns = dummies.columns.str.replace(':', '')\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47be3586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import numpy as np\n",
    "# df.fillna(0,inplace=True)\n",
    "df=df[df['date']<date(2025, 7, 1)]\n",
    "\n",
    "after_dt=None\n",
    "def recode_task_sw(var):\n",
    "    after_dt=df[df[var]==True]['date'].iloc[0]\n",
    "    df[var]=np.where(df['date']>=after_dt,1,0)\n",
    "recode_task_sw('task_ACMaintenanceHardStartKitwith/withoutPotentialRelay')\n",
    "recode_task_sw('task_ACMaintenanceNewFan')\n",
    "recode_task_sw('task_ACMaintenanceReplaceTemperatureSensor')\n",
    "recode_task_sw('task_BatteryPanelInstallation')\n",
    "recode_task_sw('task_Reinsulation')\n",
    "recode_task_sw('task_ReplacedWindows')\n",
    "\n",
    "df=df[['date','kwh','tmin', 'tmax', 'tavg',\n",
    "       'task_ACMaintenanceHardStartKitwith/withoutPotentialRelay',\n",
    "       'task_ACMaintenanceNewFan',\n",
    "       'task_ACMaintenanceReplaceTemperatureSensor',\n",
    "       'task_BatteryPanelInstallation',\n",
    "       'task_Reinsulation',\n",
    "       'task_ReplacedWindows']]\n",
    "\n",
    "pre = df[df['date'] < date(2025, 1, 1)]\n",
    "post = df[df['date'] >= date(2025, 1, 1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3fdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case = {\n",
    "    \"target\": \"kwh\",\n",
    "    \"frequency\": \"daily\",\n",
    "    \"forecast_horizon\": 30,  # 30 days ahead\n",
    "    \"exog_features\": [\"tmax\", \"tmin\"],\n",
    "    \"constraints\": {\"interpretability\": True}\n",
    "}\n",
    "\n",
    "y = df[use_case[\"target\"]]\n",
    "exog = df[use_case[\"exog_features\"]] if use_case[\"exog_features\"] else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4677e145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the use case with a target variable of \"kwh\", daily frequency, a 30-day forecast horizon, exogenous features ('tmax', 'tmin'), and an emphasis on interpretability, I suggest the following forecasting approaches:\n",
      "\n",
      "1. **SARIMAX (Seasonal Autoregressive Integrated Moving Average with Exogenous Variables)**: This model is straightforward to interpret, handles seasonality, and can include exogenous variables.\n",
      "\n",
      "2. **Facebook Prophet**: Designed for daily data with holidays or seasonality effects, easy to use, and offers components decomposition for interpretability.\n",
      "\n",
      "3. **Random Forest Regressor**: A tree-based machine learning approach which, despite being less interpretable than the above, offers variable importance metrics to gauge the influence of predictors.\n",
      "\n",
      "Here is Python code for each of these approaches:\n",
      "\n",
      "### 1. SARIMAX\n",
      "```python\n",
      "import pandas as pd\n",
      "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
      "\n",
      "# Assuming `data` is your DataFrame and has been preprocessed\n",
      "\n",
      "# Define model\n",
      "sarimax_model = SARIMAX(data['kwh'], \n",
      "                        exog=data[['tmax', 'tmin']], \n",
      "                        order=(1, 1, 1), \n",
      "                        seasonal_order=(1, 1, 1, 7))\n",
      "\n",
      "# Fit model\n",
      "sarimax_results = sarimax_model.fit()\n",
      "\n",
      "# Forecast\n",
      "forecast_exog = data[['tmax', 'tmin']].iloc[-30:]  # Adjust to future exogenous variables\n",
      "sarimax_forecast = sarimax_results.get_forecast(steps=30, exog=forecast_exog)\n",
      "print(sarimax_forecast.summary_frame())\n",
      "```\n",
      "\n",
      "### 2. Facebook Prophet\n",
      "```python\n",
      "from fbprophet import Prophet\n",
      "import pandas as pd\n",
      "\n",
      "# Format data\n",
      "prophet_data = data[['date', 'kwh']].rename(columns={'date': 'ds', 'kwh': 'y'})\n",
      "\n",
      "# Add exogenous regressors\n",
      "prophet_data['tmax'] = data['tmax']\n",
      "prophet_data['tmin'] = data['tmin']\n",
      "\n",
      "# Initialize and fit model\n",
      "prophet_model = Prophet()\n",
      "prophet_model.add_regressor('tmax')\n",
      "prophet_model.add_regressor('tmin')\n",
      "prophet_model.fit(prophet_data)\n",
      "\n",
      "# Create future dataframe\n",
      "future = prophet_model.make_future_dataframe(periods=30)\n",
      "future['tmax'] = data['tmax']  # Extend this with future data\n",
      "future['tmin'] = data['tmin']  # Extend this with future data\n",
      "\n",
      "# Forecast\n",
      "forecast = prophet_model.predict(future)\n",
      "print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(30))\n",
      "```\n",
      "\n",
      "### 3. Random Forest Regressor\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# Prepare data\n",
      "features = data[['tmax', 'tmin']]\n",
      "target = data['kwh']\n",
      "\n",
      "# Split data\n",
      "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
      "\n",
      "# Define and fit the model\n",
      "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
      "rf_model.fit(X_train, y_train)\n",
      "\n",
      "# Forecast (here, we're predicting on the test set for demonstration)\n",
      "rf_forecast = rf_model.predict(X_test)\n",
      "print(rf_forecast)\n",
      "```\n",
      "\n",
      "Each of these models has its strengths. SARIMAX and Prophet are more interpretable, especially beneficial when needing to understand seasonal effects and exogenous impacts, whereas Random Forest offers strong predictive power with variable importance scores, albeit less interpretability. Consider the trade-offs when selecting the model based on your specific interpretability and forecasting needs.\n"
     ]
    }
   ],
   "source": [
    "def get_model_suggestions(use_case, sample_data):\n",
    "    prompt = f\"\"\"\n",
    "    Given the following use case: {use_case}\n",
    "    and a sample of the data: {sample_data.head(10).to_dict()},\n",
    "    suggest 2-3 forecasting model approaches (SARIMAX, Prophet, or ML-based).\n",
    "    Provide Python code for each.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a time-series modeling assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "model_suggestions = get_model_suggestions(use_case, df)\n",
    "print(model_suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c24ce74",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    }\n",
    " \n",
    "# Example: Run SARIMAX (initial baseline)\n",
    "train = y[:-use_case[\"forecast_horizon\"]]\n",
    "test = y[-use_case[\"forecast_horizon\"]:]\n",
    "\n",
    "sarimax = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,52), exog=exog[:-use_case[\"forecast_horizon\"]])\n",
    "sarimax_fit = sarimax.fit()\n",
    "y_pred = sarimax_fit.forecast(steps=use_case[\"forecast_horizon\"], exog=exog[-use_case[\"forecast_horizon\"]:])\n",
    "results.append(evaluate_model(test, y_pred, \"SARIMAX\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d1ec55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To improve your forecasting results, you can consider several strategies, including refining the current SARIMAX model, trying different configurations, or exploring alternative models. Below are some suggestions along with Python code snippets to guide your exploration:\n",
      "\n",
      "### 1. Refining the SARIMAX Model\n",
      "\n",
      "- **Hyperparameter Tuning**: Tweak the order of the SARIMAX model (p, d, q) and seasonal order (P, D, Q, s) to find a better fit.\n",
      "- **Model Diagnostics**: Check residual diagnostics to ensure there is no autocorrelation and that residuals are white noise.\n",
      "\n",
      "```python\n",
      "import itertools\n",
      "import warnings\n",
      "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
      "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
      "import numpy as np\n",
      "\n",
      "warnings.filterwarnings(\"ignore\")\n",
      "\n",
      "# Assume you have a time series data `y` and a seasonal order `s`\n",
      "# Define the d and D parameters based on prior knowledge of the data or testing\n",
      "d = 1\n",
      "D = 1\n",
      "s = 12  # Example for monthly data\n",
      "\n",
      "# Define p, q, P, and Q ranges\n",
      "p = q = P = Q = range(0, 3)\n",
      "\n",
      "# Generate all combinations of p, q, P, Q\n",
      "pdq = list(itertools.product(p, d, q))\n",
      "seasonal_pdq = [(x[0], D, x[1], s) for x in itertools.product(P, Q)]\n",
      "\n",
      "best_aic = np.inf\n",
      "best_order = None\n",
      "best_seasonal_order = None\n",
      "\n",
      "for order in pdq:\n",
      "    for seasonal_order in seasonal_pdq:\n",
      "        try:\n",
      "            model = SARIMAX(y, order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
      "            results = model.fit()\n",
      "            \n",
      "            if results.aic < best_aic:\n",
      "                best_aic = results.aic\n",
      "                best_order = order\n",
      "                best_seasonal_order = seasonal_order\n",
      "        except:\n",
      "            continue\n",
      "\n",
      "print(f'Best SARIMAX order: {best_order}, Seasonal order: {best_seasonal_order}, AIC: {best_aic}')\n",
      "```\n",
      "\n",
      "### 2. Exploring Alternative Models\n",
      "\n",
      "#### A. Exponential Smoothing (ETS) Models\n",
      "\n",
      "```python\n",
      "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
      "\n",
      "# Fit the model\n",
      "model = ExponentialSmoothing(y, seasonal='add', seasonal_periods=s).fit()\n",
      "\n",
      "# Forecast\n",
      "y_pred = model.forecast(steps=forecast_steps)\n",
      "mae = mean_absolute_error(test, y_pred)\n",
      "rmse = mean_squared_error(test, y_pred, squared=False)\n",
      "print(f'ETS Model -> MAE: {mae}, RMSE: {rmse}')\n",
      "```\n",
      "\n",
      "#### B. Prophet\n",
      "\n",
      "Facebook's Prophet is another sophisticated model for time series forecasting, especially when seasonality is strong and there are holidays.\n",
      "\n",
      "```python\n",
      "from prophet import Prophet\n",
      "\n",
      "# Preparing the data\n",
      "df['ds'] = df.index\n",
      "df['y'] = df['value']\n",
      "\n",
      "# Fitting Prophet model\n",
      "model = Prophet(seasonality_mode='additive', yearly_seasonality=True)\n",
      "model.fit(df)\n",
      "\n",
      "# Forecasting\n",
      "future = model.make_future_dataframe(periods=forecast_steps)\n",
      "forecast = model.predict(future)\n",
      "\n",
      "# Evaluate\n",
      "y_pred = forecast['yhat'][-forecast_steps:]\n",
      "mae = mean_absolute_error(test, y_pred)\n",
      "rmse = mean_squared_error(test, y_pred, squared=False)\n",
      "print(f'Prophet Model -> MAE: {mae}, RMSE: {rmse}')\n",
      "```\n",
      "\n",
      "### 3. Additional Techniques\n",
      "\n",
      "- **Box-Cox Transformation**: Apply it to stabilize variance and make the series more normally distributed.\n",
      "- **Feature Engineering**: Include exogenous variables (if SARIMAX is used) that can help predict the series.\n",
      "\n",
      "All the code assumes you have `y` as your time series data, and `test` as the test data set to compute errors. You may need to adjust variable names and configurations according to your specific needs and dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def refine_with_llm(results):\n",
    "    prompt = f\"\"\"\n",
    "    Model results: {results}.\n",
    "    Suggest refinements or new models (include Python code).\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a time-series modeling assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "refinements = refine_with_llm(results)\n",
    "print(refinements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fe226fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARIMAX</td>\n",
       "      <td>5.566508</td>\n",
       "      <td>6.561775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model       MAE      RMSE\n",
       "0  SARIMAX  5.566508  6.561775"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(results).sort_values(\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8806e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
